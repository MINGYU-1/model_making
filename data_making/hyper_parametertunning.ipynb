{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91885487",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-23 20:04:19,968]\u001b[0m A new study created in memory with name: no-name-b133c32c-23ad-4253-8bab-8c8923c7da27\u001b[0m\n",
      "\u001b[32m[I 2026-01-23 20:04:38,784]\u001b[0m Trial 0 finished with value: 6.623849216260408 and parameters: {'lr': 0.00012202850206809438, 'z_dim': 28, 'alpha': 1.649311977256356, 'beta': 0.06591208039212863, 'gamma': 6.305661915211629}. Best is trial 0 with value: 6.623849216260408.\u001b[0m\n",
      "\u001b[32m[I 2026-01-23 20:04:52,547]\u001b[0m Trial 1 finished with value: 3.342386245727539 and parameters: {'lr': 0.0003226516839747432, 'z_dim': 8, 'alpha': 2.6752288784387384, 'beta': 0.0685914693164728, 'gamma': 0.8448321864548642}. Best is trial 1 with value: 3.342386245727539.\u001b[0m\n",
      "\u001b[32m[I 2026-01-23 20:05:06,545]\u001b[0m Trial 2 finished with value: 3.2732495508695902 and parameters: {'lr': 0.0008547619347206726, 'z_dim': 27, 'alpha': 1.7271285430701393, 'beta': 0.009528470783378606, 'gamma': 3.3709070530985104}. Best is trial 2 with value: 3.2732495508695902.\u001b[0m\n",
      "\u001b[32m[I 2026-01-23 20:05:20,527]\u001b[0m Trial 3 finished with value: 4.603539303729408 and parameters: {'lr': 0.004407835527220571, 'z_dim': 8, 'alpha': 3.5980528559220115, 'beta': 0.004879163169195705, 'gamma': 7.942309720245996}. Best is trial 2 with value: 3.2732495508695902.\u001b[0m\n",
      "\u001b[32m[I 2026-01-23 20:05:34,846]\u001b[0m Trial 4 finished with value: 9.25998366506476 and parameters: {'lr': 0.00010761836128233986, 'z_dim': 11, 'alpha': 2.3110706848988474, 'beta': 0.05694845498071775, 'gamma': 7.10270311442253}. Best is trial 2 with value: 3.2732495508695902.\u001b[0m\n",
      "\u001b[32m[I 2026-01-23 20:05:36,207]\u001b[0m Trial 5 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-23 20:05:37,862]\u001b[0m Trial 6 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-23 20:05:51,480]\u001b[0m Trial 7 finished with value: 2.956074702112298 and parameters: {'lr': 0.003524649296299454, 'z_dim': 12, 'alpha': 2.3709388512569487, 'beta': 0.026720577407187973, 'gamma': 4.011650858751664}. Best is trial 7 with value: 2.956074702112298.\u001b[0m\n",
      "\u001b[32m[I 2026-01-23 20:05:53,687]\u001b[0m Trial 8 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-23 20:05:53,973]\u001b[0m Trial 9 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-23 20:06:07,878]\u001b[0m Trial 10 finished with value: 0.5252778216412193 and parameters: {'lr': 0.007793397225765043, 'z_dim': 15, 'alpha': 0.19492291730775158, 'beta': 0.033483690577749727, 'gamma': 3.649164318497943}. Best is trial 10 with value: 0.5252778216412193.\u001b[0m\n",
      "\u001b[32m[I 2026-01-23 20:06:22,139]\u001b[0m Trial 11 finished with value: 0.26899224362875285 and parameters: {'lr': 0.00990773164159388, 'z_dim': 16, 'alpha': 0.10303825918982445, 'beta': 0.035111478795261046, 'gamma': 3.488333958070821}. Best is trial 11 with value: 0.26899224362875285.\u001b[0m\n",
      "\u001b[32m[I 2026-01-23 20:06:36,730]\u001b[0m Trial 12 finished with value: 0.37406866840626063 and parameters: {'lr': 0.009758275591108883, 'z_dim': 18, 'alpha': 0.13895777620360855, 'beta': 0.03476450464585817, 'gamma': 2.3737042236015737}. Best is trial 11 with value: 0.26899224362875285.\u001b[0m\n",
      "\u001b[32m[I 2026-01-23 20:06:50,969]\u001b[0m Trial 13 finished with value: 1.1233799175212258 and parameters: {'lr': 0.00890447022979247, 'z_dim': 20, 'alpha': 0.6065338732224318, 'beta': 0.04199148006485263, 'gamma': 1.5549785962198248}. Best is trial 11 with value: 0.26899224362875285.\u001b[0m\n",
      "\u001b[32m[I 2026-01-23 20:07:05,801]\u001b[0m Trial 14 finished with value: 1.2792240004790456 and parameters: {'lr': 0.0017928663462958663, 'z_dim': 18, 'alpha': 0.7274060076900922, 'beta': 0.042654089133939276, 'gamma': 2.1926169994691884}. Best is trial 11 with value: 0.26899224362875285.\u001b[0m\n",
      "\u001b[32m[I 2026-01-23 20:07:20,090]\u001b[0m Trial 15 finished with value: 0.7084111508570219 and parameters: {'lr': 0.005845900198144308, 'z_dim': 23, 'alpha': 0.9062779383765777, 'beta': 0.03003539035575821, 'gamma': 0.178550096921263}. Best is trial 11 with value: 0.26899224362875285.\u001b[0m\n",
      "\u001b[32m[I 2026-01-23 20:07:34,076]\u001b[0m Trial 16 finished with value: 0.4471954428835919 and parameters: {'lr': 0.0018812803794540827, 'z_dim': 15, 'alpha': 0.17570695198607733, 'beta': 0.08299377341820746, 'gamma': 2.8685787768613116}. Best is trial 11 with value: 0.26899224362875285.\u001b[0m\n",
      "\u001b[32m[I 2026-01-23 20:07:34,630]\u001b[0m Trial 17 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-23 20:07:48,396]\u001b[0m Trial 18 finished with value: 0.5570370609823027 and parameters: {'lr': 0.0046044664075555, 'z_dim': 15, 'alpha': 0.23353628695231562, 'beta': 0.02041782455024418, 'gamma': 2.1302238621840863}. Best is trial 11 with value: 0.26899224362875285.\u001b[0m\n",
      "\u001b[32m[I 2026-01-23 20:07:48,692]\u001b[0m Trial 19 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-23 20:07:48,989]\u001b[0m Trial 20 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-23 20:08:03,099]\u001b[0m Trial 21 finished with value: 0.7244338706920022 and parameters: {'lr': 0.0065937385481994425, 'z_dim': 15, 'alpha': 0.3278759576776128, 'beta': 0.08973937213523679, 'gamma': 2.748872221173414}. Best is trial 11 with value: 0.26899224362875285.\u001b[0m\n",
      "\u001b[32m[I 2026-01-23 20:08:17,285]\u001b[0m Trial 22 finished with value: 0.47190438446245697 and parameters: {'lr': 0.0019861537432144315, 'z_dim': 17, 'alpha': 0.21267730295577228, 'beta': 0.08221390206277197, 'gamma': 1.3889042984326845}. Best is trial 11 with value: 0.26899224362875285.\u001b[0m\n",
      "\u001b[32m[I 2026-01-23 20:08:17,572]\u001b[0m Trial 23 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-23 20:08:17,854]\u001b[0m Trial 24 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-23 20:08:18,146]\u001b[0m Trial 25 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-23 20:08:18,427]\u001b[0m Trial 26 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-23 20:08:18,714]\u001b[0m Trial 27 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-23 20:08:32,687]\u001b[0m Trial 28 finished with value: 0.1445702988850443 and parameters: {'lr': 0.006766126204772056, 'z_dim': 21, 'alpha': 0.11166089758490058, 'beta': 0.03679915945155675, 'gamma': 0.14792382594314013}. Best is trial 28 with value: 0.1445702988850443.\u001b[0m\n",
      "\u001b[32m[I 2026-01-23 20:08:32,981]\u001b[0m Trial 29 pruned. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Best hyperparameters: {'lr': 0.006766126204772056, 'z_dim': 21, 'alpha': 0.11166089758490058, 'beta': 0.03679915945155675, 'gamma': 0.14792382594314013}\n",
      "Best validation loss: 0.1445702988850443\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import joblib\n",
    "import optuna\n",
    "from model.model_bce_mse import MultiDecoderCondVAE, integrated_loss_fn\n",
    "\n",
    "# 1. 환경 및 데이터 준비\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 데이터 로더 및 스케일러 로드\n",
    "x_scaler = joblib.load('./torch/x_scaler.pkl')\n",
    "train_loader = torch.load('torch/train_loader.pt', weights_only=False)\n",
    "val_loader = torch.load('torch/val_loader.pt', weights_only=False)\n",
    "\n",
    "# 입력 차원 자동 추출 (첫 번째 배치를 통해 확인)\n",
    "x_sample, c_sample = next(iter(train_loader))\n",
    "x_dim = x_sample.shape[1]\n",
    "c_dim = c_sample.shape[1]\n",
    "z1_dim = 32  # 기존 코드의 기본값 활용\n",
    "\n",
    "def objective(trial):\n",
    "    # 2. 튜닝할 하이퍼파라미터 제안\n",
    "    lr = trial.suggest_float(\"lr\", 1e-4, 1e-2, log=True)\n",
    "    z_dim = trial.suggest_int(\"z_dim\", 4, 32)\n",
    "    alpha = trial.suggest_float(\"alpha\", 0.1, 5.0)\n",
    "    beta = trial.suggest_float(\"beta\", 0.001, 0.1) # KL 가중치는 보통 작게 시작\n",
    "    gamma = trial.suggest_float(\"gamma\", 0.1, 10.0)\n",
    "    \n",
    "    # 3. 모델 및 옵티마이저 선언\n",
    "    model = MultiDecoderCondVAE(x_dim, c_dim, z_dim, z1_dim).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    # 각 trial당 학습할 에포크 수 (성능 확인을 위해 최소 20~50회 권장)\n",
    "    epochs = 50 \n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # --- Training Loop ---\n",
    "        model.train()\n",
    "        for x, c in train_loader:\n",
    "            x, c = x.to(device), c.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            mask_logits, prob_mask, mask_out, recon_numeric, z_mu, z_logvar = model(x, c)\n",
    "            \n",
    "            # integrated_loss_fn에 제안된 가중치 적용\n",
    "            loss_dict = integrated_loss_fn(\n",
    "                mask_logits, recon_numeric, x, z_mu, z_logvar, \n",
    "                alpha=alpha, beta=beta, gamma=gamma\n",
    "            )\n",
    "            \n",
    "            loss_dict['loss'].backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        # --- Validation Loop ---\n",
    "        model.eval()\n",
    "        v_total_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for v_x, v_c in val_loader:\n",
    "                v_x, v_c = v_x.to(device), v_c.to(device)\n",
    "                v_mask_logits, _, _, v_recon_numeric, v_z_mu, v_z_logvar = model(v_x, v_c)\n",
    "                \n",
    "                v_loss_dict = integrated_loss_fn(\n",
    "                    v_mask_logits, v_recon_numeric, v_x, v_z_mu, v_z_logvar,\n",
    "                    alpha=alpha, beta=beta, gamma=gamma\n",
    "                )\n",
    "                v_total_loss += v_loss_dict['loss'].item()\n",
    "        \n",
    "        avg_val_loss = v_total_loss / len(val_loader)\n",
    "        \n",
    "        # Pruning: 성능이 개선되지 않는 trial은 조기 종료하여 시간 절약\n",
    "        trial.report(avg_val_loss, epoch)\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return avg_val_loss\n",
    "\n",
    "# 4. 최적화 실행\n",
    "# n_trials: 총 시도 횟수 (예: 30)\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=30)\n",
    "\n",
    "# 5. 최적화 결과 확인 및 모델 재학습 활용\n",
    "print(\"-\" * 30)\n",
    "print(\"Best hyperparameters:\", study.best_params)\n",
    "print(\"Best validation loss:\", study.best_value)\n",
    "\n",
    "# 6. (선택) 파라미터 중요도 시각화\n",
    "# optuna.visualization.plot_param_importances(study).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
