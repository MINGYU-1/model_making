{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91885487",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-24 20:58:36,817]\u001b[0m A new study created in memory with name: no-name-f9db33a9-5946-4ca6-ac21-7bb3b31b28bd\u001b[0m\n",
      "\u001b[32m[I 2026-01-24 20:59:14,690]\u001b[0m Trial 0 finished with value: 1.0965825395756645 and parameters: {'lr': 0.0003695525379950842, 'z_dim': 17, 'alpha': 3.816247271299659, 'beta': 0.08592815081862576, 'gamma': 9.688937223583396}. Best is trial 0 with value: 1.0965825395756645.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import joblib\n",
    "import optuna\n",
    "from model.m24odel import MultiDecoderCondVAE\n",
    "from loss.l24oss_bce_mse import integrated_loss_fn\n",
    "\n",
    "# 1. 환경 및 데이터 준비\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 데이터 로더 및 스케일러 로드\n",
    "x_scaler = joblib.load('./torch/x_scaler.pkl')\n",
    "train_loader = torch.load('torch/train_loader_a_r.pt', weights_only=False)\n",
    "val_loader = torch.load('torch/val_loader_a_r.pt', weights_only=False)\n",
    "\n",
    "# 입력 차원 자동 추출 (첫 번째 배치를 통해 확인)\n",
    "x_sample, c_sample = next(iter(train_loader))\n",
    "x_dim = x_sample.shape[1]\n",
    "c_dim = c_sample.shape[1]\n",
    "z1_dim = 32  # 기존 코드의 기본값 활용\n",
    "\n",
    "def objective(trial):\n",
    "    # 2. 튜닝할 하이퍼파라미터 제안\n",
    "    lr = trial.suggest_float(\"lr\", 1e-4, 1e-2, log=True)\n",
    "    z_dim = trial.suggest_int(\"z_dim\", 4, 32)\n",
    "    alpha = trial.suggest_float(\"alpha\", 0.1, 5.0)\n",
    "    beta = trial.suggest_float(\"beta\", 0.001, 0.1) # KL 가중치는 보통 작게 시작\n",
    "    gamma = trial.suggest_float(\"gamma\", 0.1, 10.0)\n",
    "    \n",
    "    # 3. 모델 및 옵티마이저 선언\n",
    "    model = MultiDecoderCondVAE(x_dim, c_dim, z_dim, z1_dim).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    # 각 trial당 학습할 에포크 수 (성능 확인을 위해 최소 20~50회 권장)\n",
    "    epochs = 50 \n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # --- Training Loop ---\n",
    "        model.train()\n",
    "        for x, c in train_loader:\n",
    "            x, c = x.to(device), c.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            mask_logits, prob_mask, recon_numeric, z_mu, z_logvar = model(x, c)\n",
    "            \n",
    "            # integrated_loss_fn에 제안된 가중치 적용\n",
    "            loss_dict = integrated_loss_fn(\n",
    "                mask_logits, recon_numeric, x, z_mu, z_logvar, \n",
    "                alpha=alpha, beta=beta, gamma=gamma\n",
    "            )\n",
    "            \n",
    "            loss_dict['loss'].backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        # --- Validation Loop ---\n",
    "        model.eval()\n",
    "        v_total_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for v_x, v_c in val_loader:\n",
    "                v_x, v_c = v_x.to(device), v_c.to(device)\n",
    "                v_mask_logits,_, v_recon_numeric, v_z_mu, v_z_logvar = model(v_x, v_c)\n",
    "                \n",
    "                v_loss_dict = integrated_loss_fn(\n",
    "                    v_mask_logits, v_recon_numeric, v_x, v_z_mu, v_z_logvar,\n",
    "                    alpha=alpha, beta=beta, gamma=gamma\n",
    "                )\n",
    "                v_total_loss += v_loss_dict['loss'].item()\n",
    "        \n",
    "        avg_val_loss = v_total_loss / len(val_loader)\n",
    "        \n",
    "        # Pruning: 성능이 개선되지 않는 trial은 조기 종료하여 시간 절약\n",
    "        trial.report(avg_val_loss, epoch)\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return avg_val_loss\n",
    "\n",
    "# 4. 최적화 실행\n",
    "# n_trials: 총 시도 횟수 (예: 30)\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=30)\n",
    "\n",
    "# 5. 최적화 결과 확인 및 모델 재학습 활용\n",
    "print(\"-\" * 30)\n",
    "print(\"Best hyperparameters:\", study.best_params)\n",
    "print(\"Best validation loss:\", study.best_value)\n",
    "\n",
    "# 6. (선택) 파라미터 중요도 시각화\n",
    "# optuna.visualization.plot_param_importances(study).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
