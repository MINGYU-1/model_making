{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f0b9578",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 현재 경로 확인\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# 1단계 상위 디렉토리 경로 생성\n",
    "parent_dir = os.path.abspath(os.path.join(current_dir, os.pardir))\n",
    "\n",
    "\n",
    "os.chdir(parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a53cb63e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.0e+02, 5.0e+01, 5.0e+01, ..., 4.0e+00, 6.0e+01, 8.1e+01],\n",
       "       [7.5e+02, 5.0e+01, 5.0e+01, ..., 4.0e+00, 6.0e+01, 9.0e+01],\n",
       "       [7.5e+02, 5.0e+01, 5.0e+01, ..., 4.0e+00, 6.0e+01, 9.1e+01],\n",
       "       ...,\n",
       "       [8.0e+02, 2.5e+01, 2.5e+01, ..., 5.0e-01, 1.2e+02, 9.5e+01],\n",
       "       [8.5e+02, 2.5e+01, 2.5e+01, ..., 5.0e-01, 1.2e+02, 9.7e+01],\n",
       "       [9.0e+02, 2.5e+01, 2.5e+01, ..., 5.0e-01, 1.2e+02, 9.8e+01]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "c_data = np.load('data/reaction.npy')\n",
    "c_data[c_data[:,-1]>80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10795e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train] labeled: 694 / unlabeled: 2850\n",
      "[val]   1182\n",
      "[test]  1182\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import joblib\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MaxAbsScaler,StandardScaler\n",
    "\n",
    "# -----------------------\n",
    "# 0) Load\n",
    "# -----------------------\n",
    "x_data = np.load('./data/active.npy')      # (N, x_dim)\n",
    "c_all  = np.load('./data/reaction.npy')    # (N, c_dim+1)  마지막 열이 y라고 가정\n",
    "# s_data = np.load('./data/promoter.npy')  # 필요하면 아래에 같이 붙이면 됨\n",
    "\n",
    "# -----------------------\n",
    "# 1) Split c -> (c_feat, y)\n",
    "# -----------------------\n",
    "c_feat = c_all.astype(np.float32)  # 조건 입력\n",
    "y_data = c_all[:, -1].astype(np.float32)   # conversion 라벨\n",
    "\n",
    "x_data = x_data.astype(np.float32)\n",
    "\n",
    "# -----------------------\n",
    "# 2) Train/Val/Test split (0.6 / 0.2 / 0.2)\n",
    "#    (라벨/비라벨 분리는 train 내부에서만 진행)\n",
    "# -----------------------\n",
    "x_train, x_tmp, c_train, c_tmp, y_train, y_tmp = train_test_split(\n",
    "    x_data, c_feat, y_data, test_size=0.4, random_state=21\n",
    ")\n",
    "x_val, x_test, c_val, c_test, y_val, y_test = train_test_split(\n",
    "    x_tmp, c_tmp, y_tmp, test_size=0.5, random_state=21\n",
    ")\n",
    "\n",
    "# -----------------------\n",
    "# 3) Scaling (fit은 train만)\n",
    "# -----------------------\n",
    "x_scaler = MaxAbsScaler()\n",
    "c_scaler = StandardScaler()\n",
    "\n",
    "x_train_s = x_scaler.fit_transform(x_train)\n",
    "c_train_s = c_scaler.fit_transform(c_train)\n",
    "\n",
    "x_val_s  = x_scaler.transform(x_val)\n",
    "x_test_s = x_scaler.transform(x_test)\n",
    "\n",
    "c_val_s  = c_scaler.transform(c_val)\n",
    "c_test_s = c_scaler.transform(c_test)\n",
    "\n",
    "os.makedirs('./torch', exist_ok=True)\n",
    "joblib.dump(x_scaler, './torch/25x_scaler.pkl')\n",
    "joblib.dump(c_scaler, './torch/25c_scaler.pkl')\n",
    "\n",
    "# -----------------------\n",
    "# 4) Make labeled/unlabeled split INSIDE TRAIN\n",
    "#    rule: y > 80  -> labeled\n",
    "# -----------------------\n",
    "thr = 80.0\n",
    "labeled_mask = (y_train > thr)\n",
    "unlabeled_mask = ~labeled_mask\n",
    "\n",
    "xL = x_train_s[labeled_mask]\n",
    "cL = c_train_s[labeled_mask]\n",
    "yL = y_train[labeled_mask]        # y는 스케일링 안 함(원하면 따로 scaler 추가)\n",
    "\n",
    "xU = x_train_s[unlabeled_mask]\n",
    "cU = c_train_s[unlabeled_mask]\n",
    "\n",
    "# -----------------------\n",
    "# 5) Torch tensors\n",
    "# -----------------------\n",
    "def to_torch(a):\n",
    "    return torch.tensor(a, dtype=torch.float32)\n",
    "\n",
    "xL_t, cL_t, yL_t = to_torch(xL), to_torch(cL), to_torch(yL).unsqueeze(1)  # (nL, 1)\n",
    "xU_t, cU_t       = to_torch(xU), to_torch(cU)\n",
    "\n",
    "xV_t, cV_t, yV_t = to_torch(x_val_s),  to_torch(c_val_s),  to_torch(y_val).unsqueeze(1)\n",
    "xT_t, cT_t, yT_t = to_torch(x_test_s), to_torch(c_test_s), to_torch(y_test).unsqueeze(1)\n",
    "\n",
    "# -----------------------\n",
    "# 6) Datasets / Loaders\n",
    "# -----------------------\n",
    "labeled_train_ds   = TensorDataset(xL_t, cL_t, yL_t)  # (x,c,y)\n",
    "unlabeled_train_ds = TensorDataset(xU_t, cU_t)        # (x,c)\n",
    "\n",
    "val_ds  = TensorDataset(xV_t, cV_t, yV_t)             # 검증은 y로 성능 확인\n",
    "test_ds = TensorDataset(xT_t, cT_t, yT_t)\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "labeled_loader = DataLoader(labeled_train_ds, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "unlabeled_loader = DataLoader(unlabeled_train_ds, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "val_loader  = DataLoader(val_ds,  batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# -----------------------\n",
    "# 7) Save loaders (추천: dataset 저장이 더 안전하지만, 요청대로 loader 저장)\n",
    "# -----------------------\n",
    "torch.save(labeled_loader,   \"./torch/labeled_train_loader_ar.pt\")\n",
    "torch.save(unlabeled_loader, \"./torch/unlabeled_train_loader_ar.pt\")\n",
    "torch.save(val_loader,       \"./torch/val_loader_ar.pt\")\n",
    "torch.save(test_loader,      \"./torch/test_loader_ar.pt\")\n",
    "\n",
    "print(f\"[train] labeled: {len(labeled_train_ds)} / unlabeled: {len(unlabeled_train_ds)}\")\n",
    "print(f\"[val]   {len(val_ds)}\")\n",
    "print(f\"[test]  {len(test_ds)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
