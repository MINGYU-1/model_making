{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91885487",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-24 22:23:58,964]\u001b[0m A new study created in memory with name: no-name-01b8045a-ddb4-4e40-98aa-7e69733f425d\u001b[0m\n",
      "\u001b[32m[I 2026-01-24 22:24:28,136]\u001b[0m Trial 0 finished with value: 1.5313441063228406 and parameters: {'lr': 0.0001565872486496606, 'z_dim': 17, 'alpha': 3.1430663131668375, 'beta': 0.003461132603689933, 'gamma': 9.15793449868126, 'surr': 9.700462501755151}. Best is trial 0 with value: 1.5313441063228406.\u001b[0m\n",
      "\u001b[32m[I 2026-01-24 22:24:56,177]\u001b[0m Trial 1 finished with value: 0.07425849767107713 and parameters: {'lr': 0.001963425243783516, 'z_dim': 9, 'alpha': 1.477217570906519, 'beta': 0.08019077589763333, 'gamma': 2.89160769707184, 'surr': 6.8717754405347575}. Best is trial 1 with value: 0.07425849767107713.\u001b[0m\n",
      "\u001b[32m[I 2026-01-24 22:25:24,099]\u001b[0m Trial 2 finished with value: 2.1627331532930074 and parameters: {'lr': 0.00013018634425749327, 'z_dim': 11, 'alpha': 4.300177074181566, 'beta': 0.03711772901963314, 'gamma': 2.684547756570741, 'surr': 6.025291841917875}. Best is trial 1 with value: 0.07425849767107713.\u001b[0m\n",
      "\u001b[32m[I 2026-01-24 22:25:51,534]\u001b[0m Trial 3 finished with value: 0.06986801757624275 and parameters: {'lr': 0.0009456748954398215, 'z_dim': 21, 'alpha': 0.31280144906076673, 'beta': 0.03737750536772139, 'gamma': 4.266115916302099, 'surr': 8.169442259060746}. Best is trial 3 with value: 0.06986801757624275.\u001b[0m\n",
      "\u001b[32m[I 2026-01-24 22:26:18,330]\u001b[0m Trial 4 finished with value: 0.054693602417644704 and parameters: {'lr': 0.0017870640422456051, 'z_dim': 4, 'alpha': 3.2137356019577235, 'beta': 0.048593132785087194, 'gamma': 1.6465538600025986, 'surr': 6.671651257642334}. Best is trial 4 with value: 0.054693602417644704.\u001b[0m\n",
      "\u001b[32m[I 2026-01-24 22:26:19,417]\u001b[0m Trial 5 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-24 22:26:46,946]\u001b[0m Trial 6 finished with value: 0.04986018001248962 and parameters: {'lr': 0.005115992983634351, 'z_dim': 5, 'alpha': 4.507596661921015, 'beta': 0.018745278723998792, 'gamma': 5.294372493304247, 'surr': 8.71123096081826}. Best is trial 6 with value: 0.04986018001248962.\u001b[0m\n",
      "\u001b[32m[I 2026-01-24 22:26:47,410]\u001b[0m Trial 7 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-24 22:26:48,065]\u001b[0m Trial 8 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-24 22:26:48,670]\u001b[0m Trial 9 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-24 22:27:19,332]\u001b[0m Trial 10 finished with value: 0.06605581056914832 and parameters: {'lr': 0.008378535520968646, 'z_dim': 32, 'alpha': 2.0528009168128416, 'beta': 0.06527404020475898, 'gamma': 6.002263171586993, 'surr': 0.8265804797284346}. Best is trial 6 with value: 0.04986018001248962.\u001b[0m\n",
      "\u001b[32m[I 2026-01-24 22:27:45,192]\u001b[0m Trial 11 finished with value: 0.06629976826278787 and parameters: {'lr': 0.003567111915686911, 'z_dim': 4, 'alpha': 2.9040395889865014, 'beta': 0.060745754777020974, 'gamma': 4.879409453148118, 'surr': 7.264849112656712}. Best is trial 6 with value: 0.04986018001248962.\u001b[0m\n",
      "\u001b[32m[I 2026-01-24 22:27:49,336]\u001b[0m Trial 12 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-24 22:28:12,888]\u001b[0m Trial 13 finished with value: 0.04080967683541147 and parameters: {'lr': 0.009684577131077246, 'z_dim': 4, 'alpha': 2.1793607309594965, 'beta': 0.02327598965147177, 'gamma': 3.8025632802871225, 'surr': 3.2218012088282997}. Best is trial 13 with value: 0.04080967683541147.\u001b[0m\n",
      "\u001b[32m[I 2026-01-24 22:28:38,575]\u001b[0m Trial 14 finished with value: 0.03693309004761671 and parameters: {'lr': 0.00852518710175567, 'z_dim': 12, 'alpha': 1.8938946291475096, 'beta': 0.020349331517040332, 'gamma': 6.076423260289555, 'surr': 1.8051203931324404}. Best is trial 14 with value: 0.03693309004761671.\u001b[0m\n",
      "\u001b[32m[I 2026-01-24 22:29:03,399]\u001b[0m Trial 15 finished with value: 0.060052344673558286 and parameters: {'lr': 0.009353592817421574, 'z_dim': 14, 'alpha': 1.234582985230597, 'beta': 0.031482990536583114, 'gamma': 3.731737060483014, 'surr': 1.9742082930225882}. Best is trial 14 with value: 0.03693309004761671.\u001b[0m\n",
      "\u001b[32m[I 2026-01-24 22:29:39,045]\u001b[0m Trial 16 finished with value: 0.0262140918915209 and parameters: {'lr': 0.006014265064009584, 'z_dim': 9, 'alpha': 2.0444900795589236, 'beta': 0.011016616191373872, 'gamma': 6.856404572630456, 'surr': 2.7707776976670395}. Best is trial 16 with value: 0.0262140918915209.\u001b[0m\n",
      "\u001b[32m[I 2026-01-24 22:30:18,453]\u001b[0m Trial 17 finished with value: 0.009816390217134827 and parameters: {'lr': 0.0027336337023480587, 'z_dim': 14, 'alpha': 1.0444732706911335, 'beta': 0.010274267070146335, 'gamma': 7.040291211870617, 'surr': 0.4392431415334326}. Best is trial 17 with value: 0.009816390217134827.\u001b[0m\n",
      "\u001b[32m[I 2026-01-24 22:30:53,661]\u001b[0m Trial 18 finished with value: 0.007518944109937078 and parameters: {'lr': 0.002340676083161239, 'z_dim': 17, 'alpha': 0.45625233844770874, 'beta': 0.008741819437673534, 'gamma': 7.904571367621319, 'surr': 0.18187154919450677}. Best is trial 18 with value: 0.007518944109937078.\u001b[0m\n",
      "\u001b[32m[I 2026-01-24 22:31:28,249]\u001b[0m Trial 19 finished with value: 0.008832231237504044 and parameters: {'lr': 0.0016972032553329666, 'z_dim': 19, 'alpha': 0.35854230950505617, 'beta': 0.010096934347440974, 'gamma': 8.135399664815708, 'surr': 0.2413011422901801}. Best is trial 18 with value: 0.007518944109937078.\u001b[0m\n",
      "\u001b[32m[I 2026-01-24 22:31:31,206]\u001b[0m Trial 20 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-24 22:31:31,953]\u001b[0m Trial 21 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-24 22:31:32,630]\u001b[0m Trial 22 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-24 22:31:33,290]\u001b[0m Trial 23 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-24 22:31:34,135]\u001b[0m Trial 24 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-24 22:31:34,903]\u001b[0m Trial 25 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-24 22:31:35,571]\u001b[0m Trial 26 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-24 22:31:36,146]\u001b[0m Trial 27 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-24 22:31:36,871]\u001b[0m Trial 28 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-24 22:31:37,538]\u001b[0m Trial 29 pruned. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Best hyperparameters: {'lr': 0.002340676083161239, 'z_dim': 17, 'alpha': 0.45625233844770874, 'beta': 0.008741819437673534, 'gamma': 7.904571367621319, 'surr': 0.18187154919450677}\n",
      "Best validation loss: 0.007518944109937078\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import joblib\n",
    "import optuna\n",
    "from model.m24odel import MultiDecoderCondVAE\n",
    "from loss.l24oss_all import integrated_loss_fn\n",
    "\n",
    "# 1. 환경 및 데이터 준비\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 데이터 로더 및 스케일러 로드\n",
    "x_scaler = joblib.load('torch/x_scaler.pkl')\n",
    "c_saler = joblib.load('torch/c_scaler.pkl')\n",
    "train_loader = torch.load('torch/train_loader_a_r.pt', weights_only=False)\n",
    "val_loader = torch.load('torch/val_loader_a_r.pt', weights_only=False)\n",
    "\n",
    "# 입력 차원 자동 추출 (첫 번째 배치를 통해 확인)\n",
    "x_sample, c_sample = next(iter(train_loader))\n",
    "x_dim = x_sample.shape[1]\n",
    "c_dim = c_sample.shape[1]\n",
    "z1_dim = 32  # 기존 코드의 기본값 활용\n",
    "\n",
    "def objective(trial):\n",
    "    # 2. 튜닝할 하이퍼파라미터 제안\n",
    "    lr = trial.suggest_float(\"lr\", 1e-4, 1e-2, log=True)\n",
    "    z_dim = trial.suggest_int(\"z_dim\", 4, 32)\n",
    "    alpha = trial.suggest_float(\"alpha\", 0.1, 5.0)\n",
    "    beta = trial.suggest_float(\"beta\", 0.001, 0.1) # KL 가중치는 보통 작게 시작\n",
    "    gamma = trial.suggest_float(\"gamma\", 0.1, 10.0)\n",
    "    surr = trial.suggest_float(\"surr\",0.1,10.0)\n",
    "    # 3. 모델 및 옵티마이저 선언\n",
    "    model = MultiDecoderCondVAE(x_dim, c_dim, z_dim, z1_dim).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    # 각 trial당 학습할 에포크 수 (성능 확인을 위해 최소 20~50회 권장)\n",
    "    epochs = 50 \n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # --- Training Loop ---\n",
    "        model.train()\n",
    "        for x, c in train_loader:\n",
    "            x, c = x.to(device), c.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            mask_logits, prob_mask, recon_numeric, z_mu, z_logvar,pred_con = model(x, c)\n",
    "            \n",
    "            # integrated_loss_fn에 제안된 가중치 적용\n",
    "            loss_dict = integrated_loss_fn(\n",
    "                mask_logits, recon_numeric, x, z_mu, z_logvar,pred_con, c\n",
    "                ,alpha=alpha, beta=beta, gamma=gamma, w_surr = surr\n",
    "            )\n",
    "            \n",
    "            loss_dict['loss'].backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        # --- Validation Loop ---\n",
    "        model.eval()\n",
    "        v_total_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for v_x, v_c in val_loader:\n",
    "                v_x, v_c = v_x.to(device), v_c.to(device)\n",
    "                v_mask_logits,_, v_recon_numeric, v_z_mu, v_z_logvar,v_pred = model(v_x, v_c)\n",
    "                \n",
    "                v_loss_dict = integrated_loss_fn(\n",
    "                    v_mask_logits, v_recon_numeric, v_x, v_z_mu, v_z_logvar,v_pred,v_c,\n",
    "                    alpha=alpha, beta=beta, gamma=gamma,w_surr=surr\n",
    "                )\n",
    "                v_total_loss += v_loss_dict['loss'].item()\n",
    "        \n",
    "        avg_val_loss = v_total_loss / len(val_loader)\n",
    "        \n",
    "        # Pruning: 성능이 개선되지 않는 trial은 조기 종료하여 시간 절약\n",
    "        trial.report(avg_val_loss, epoch)\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return avg_val_loss\n",
    "\n",
    "# 4. 최적화 실행\n",
    "# n_trials: 총 시도 횟수 (예: 30)\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=30)\n",
    "\n",
    "# 5. 최적화 결과 확인 및 모델 재학습 활용\n",
    "print(\"-\" * 30)\n",
    "print(\"Best hyperparameters:\", study.best_params)\n",
    "print(\"Best validation loss:\", study.best_value)\n",
    "\n",
    "# 6. (선택) 파라미터 중요도 시각화\n",
    "# optuna.visualization.plot_param_importances(study).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
