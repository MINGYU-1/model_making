{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9fda2f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "par_dir = os.path.abspath(os.path.join(os.getcwd(),os.pardir))\n",
    "os.chdir(par_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91885487",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-25 17:58:42,471]\u001b[0m A new study created in memory with name: no-name-056c6499-29bd-4fa7-a06e-928d6e69b954\u001b[0m\n",
      "\u001b[32m[I 2026-01-25 17:59:31,911]\u001b[0m Trial 0 finished with value: 1.1158811732342369 and parameters: {'lr': 0.00560666630996297, 'z_dim': 21, 'alpha': 1.205300653162256, 'beta': 0.0523023361960124, 'gamma': 6.653075259436065, 'surr': 5.101204950863943}. Best is trial 0 with value: 1.1158811732342369.\u001b[0m\n",
      "\u001b[32m[I 2026-01-25 18:00:19,307]\u001b[0m Trial 1 finished with value: 1.9211219109986957 and parameters: {'lr': 0.0022121488134155417, 'z_dim': 9, 'alpha': 4.167230462155455, 'beta': 0.06188088241915166, 'gamma': 0.7195762027853129, 'surr': 3.163758677967726}. Best is trial 0 with value: 1.1158811732342369.\u001b[0m\n",
      "\u001b[32m[I 2026-01-25 18:01:04,710]\u001b[0m Trial 2 finished with value: 7.302103820600007 and parameters: {'lr': 0.0002143288413352421, 'z_dim': 19, 'alpha': 4.697618342668655, 'beta': 0.05749950645432637, 'gamma': 2.186032647972091, 'surr': 9.32846033602447}. Best is trial 0 with value: 1.1158811732342369.\u001b[0m\n",
      "\u001b[32m[I 2026-01-25 18:01:49,795]\u001b[0m Trial 3 finished with value: 5.224941454435649 and parameters: {'lr': 0.00020819265317583758, 'z_dim': 16, 'alpha': 3.5502312252435906, 'beta': 0.05581520753946685, 'gamma': 6.454290422138845, 'surr': 0.12288716295147957}. Best is trial 0 with value: 1.1158811732342369.\u001b[0m\n",
      "\u001b[32m[I 2026-01-25 18:02:48,294]\u001b[0m Trial 4 finished with value: 5.273025700920506 and parameters: {'lr': 0.0016689958249153816, 'z_dim': 23, 'alpha': 4.790357499584861, 'beta': 0.06671047912157053, 'gamma': 4.673049482447462, 'surr': 3.256728115905731}. Best is trial 0 with value: 1.1158811732342369.\u001b[0m\n",
      "\u001b[32m[I 2026-01-25 18:02:49,661]\u001b[0m Trial 5 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-25 18:03:54,160]\u001b[0m Trial 6 finished with value: 3.14375649000469 and parameters: {'lr': 0.003536747604712889, 'z_dim': 27, 'alpha': 3.605747079900445, 'beta': 0.02821527748341871, 'gamma': 2.530278586007764, 'surr': 3.855463569090636}. Best is trial 0 with value: 1.1158811732342369.\u001b[0m\n",
      "\u001b[32m[I 2026-01-25 18:03:55,279]\u001b[0m Trial 7 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-25 18:03:56,289]\u001b[0m Trial 8 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-25 18:04:44,247]\u001b[0m Trial 9 finished with value: 0.6026403966702913 and parameters: {'lr': 0.009736900353958092, 'z_dim': 10, 'alpha': 0.43960876659099035, 'beta': 0.09377854641363324, 'gamma': 8.283478294290905, 'surr': 9.94013337928504}. Best is trial 9 with value: 0.6026403966702913.\u001b[0m\n",
      "\u001b[32m[I 2026-01-25 18:05:32,644]\u001b[0m Trial 10 finished with value: 0.33798211656118693 and parameters: {'lr': 0.009372751527134252, 'z_dim': 4, 'alpha': 0.14484577804839527, 'beta': 0.09827876947682813, 'gamma': 9.817780982531945, 'surr': 9.857028129946775}. Best is trial 10 with value: 0.33798211656118693.\u001b[0m\n",
      "\u001b[32m[I 2026-01-25 18:06:16,098]\u001b[0m Trial 11 finished with value: 0.16271844427836568 and parameters: {'lr': 0.009330350291625374, 'z_dim': 4, 'alpha': 0.11304579161474321, 'beta': 0.09602435812170919, 'gamma': 9.639183104730524, 'surr': 9.785354621255937}. Best is trial 11 with value: 0.16271844427836568.\u001b[0m\n",
      "\u001b[32m[I 2026-01-25 18:07:08,262]\u001b[0m Trial 12 finished with value: 0.19355900115088412 and parameters: {'lr': 0.009408217841971033, 'z_dim': 7, 'alpha': 0.1432520060044344, 'beta': 0.07867010032311407, 'gamma': 9.755671840551555, 'surr': 7.776985366866191}. Best is trial 11 with value: 0.16271844427836568.\u001b[0m\n",
      "\u001b[32m[I 2026-01-25 18:07:09,503]\u001b[0m Trial 13 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-25 18:07:10,554]\u001b[0m Trial 14 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-25 18:07:11,755]\u001b[0m Trial 15 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-25 18:08:12,399]\u001b[0m Trial 16 finished with value: 0.6246706137531682 and parameters: {'lr': 0.005816119956952718, 'z_dim': 11, 'alpha': 0.6667508098122557, 'beta': 0.03930492069041537, 'gamma': 8.614969605248936, 'surr': 8.239453320894684}. Best is trial 11 with value: 0.16271844427836568.\u001b[0m\n",
      "\u001b[32m[I 2026-01-25 18:08:13,499]\u001b[0m Trial 17 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-25 18:08:14,684]\u001b[0m Trial 18 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-25 18:09:05,864]\u001b[0m Trial 19 finished with value: 0.1577044031337688 and parameters: {'lr': 0.007209650083205326, 'z_dim': 7, 'alpha': 0.11702920706785994, 'beta': 0.07012716830407131, 'gamma': 9.19546202126989, 'surr': 7.816033477711758}. Best is trial 19 with value: 0.1577044031337688.\u001b[0m\n",
      "\u001b[32m[I 2026-01-25 18:09:06,993]\u001b[0m Trial 20 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-25 18:09:55,770]\u001b[0m Trial 21 finished with value: 0.368841257534529 and parameters: {'lr': 0.007126417177702542, 'z_dim': 7, 'alpha': 0.3162634485202891, 'beta': 0.08494609462119959, 'gamma': 8.962846668026181, 'surr': 7.623357765151781}. Best is trial 19 with value: 0.1577044031337688.\u001b[0m\n",
      "\u001b[32m[I 2026-01-25 18:09:58,430]\u001b[0m Trial 22 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-25 18:10:44,196]\u001b[0m Trial 23 finished with value: 0.38814711962875564 and parameters: {'lr': 0.005666432620642261, 'z_dim': 12, 'alpha': 0.3944622237019722, 'beta': 0.09106452365714568, 'gamma': 7.318354280823012, 'surr': 9.138540177083797}. Best is trial 19 with value: 0.1577044031337688.\u001b[0m\n",
      "\u001b[32m[I 2026-01-25 18:10:45,113]\u001b[0m Trial 24 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-25 18:10:46,781]\u001b[0m Trial 25 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-25 18:10:47,574]\u001b[0m Trial 26 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-25 18:10:52,104]\u001b[0m Trial 27 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-25 18:10:53,217]\u001b[0m Trial 28 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-25 18:10:54,907]\u001b[0m Trial 29 pruned. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Best hyperparameters: {'lr': 0.007209650083205326, 'z_dim': 7, 'alpha': 0.11702920706785994, 'beta': 0.07012716830407131, 'gamma': 9.19546202126989, 'surr': 7.816033477711758}\n",
      "Best validation loss: 0.1577044031337688\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import joblib\n",
    "import optuna\n",
    "from model.m25odel_1 import MultiDecoderCondVAE\n",
    "from loss.l25oss_1 import integrated_loss_fn\n",
    "\n",
    "# 1. 환경 및 데이터 준비\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 데이터 로더 및 스케일러 로드\n",
    "x_scaler = joblib.load('torch/x_scaler.pkl')\n",
    "c_saler = joblib.load('torch/c_scaler.pkl')\n",
    "train_loader = torch.load('torch/train_loader_a_r.pt', weights_only=False)\n",
    "val_loader = torch.load('torch/val_loader_a_r.pt', weights_only=False)\n",
    "\n",
    "# 입력 차원 자동 추출 (첫 번째 배치를 통해 확인)\n",
    "x_sample, c_sample = next(iter(train_loader))\n",
    "x_dim = x_sample.shape[1]\n",
    "c_dim = c_sample.shape[1]\n",
    "z1_dim = 32  # 기존 코드의 기본값 활용\n",
    "\n",
    "def objective(trial):\n",
    "    # 2. 튜닝할 하이퍼파라미터 제안\n",
    "    lr = trial.suggest_float(\"lr\", 1e-4, 1e-2, log=True)\n",
    "    z_dim = trial.suggest_int(\"z_dim\", 4, 32)\n",
    "    alpha = trial.suggest_float(\"alpha\", 0.1, 5.0)\n",
    "    beta = trial.suggest_float(\"beta\", 0.001, 0.1) # KL 가중치는 보통 작게 시작\n",
    "    gamma = trial.suggest_float(\"gamma\", 0.1, 10.0)\n",
    "    surr = trial.suggest_float(\"surr\",0.1,10.0)\n",
    "    # 3. 모델 및 옵티마이저 선언\n",
    "    model = MultiDecoderCondVAE(x_dim, c_dim, z_dim, z1_dim).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    # 각 trial당 학습할 에포크 수 (성능 확인을 위해 최소 20~50회 권장)\n",
    "    epochs = 50 \n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # --- Training Loop ---\n",
    "        model.train()\n",
    "        for x, c in train_loader:\n",
    "            x, c = x.to(device), c.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            mask_logits, prob_mask, recon_numeric, z_mu, z_logvar,pred_con = model(x, c)\n",
    "            \n",
    "            # integrated_loss_fn에 제안된 가중치 적용\n",
    "            loss_dict = integrated_loss_fn(\n",
    "                mask_logits, recon_numeric, x, z_mu, z_logvar,pred_con, c\n",
    "                ,alpha=alpha, beta=beta, gamma=gamma, w_surr = surr\n",
    "            )\n",
    "            \n",
    "            loss_dict['loss'].backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        # --- Validation Loop ---\n",
    "        model.eval()\n",
    "        v_total_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for v_x, v_c in val_loader:\n",
    "                v_x, v_c = v_x.to(device), v_c.to(device)\n",
    "                v_mask_logits,_, v_recon_numeric, v_z_mu, v_z_logvar,v_pred = model(v_x, v_c)\n",
    "                \n",
    "                v_loss_dict = integrated_loss_fn(\n",
    "                    v_mask_logits, v_recon_numeric, v_x, v_z_mu, v_z_logvar,v_pred,v_c,\n",
    "                    alpha=alpha, beta=beta, gamma=gamma,w_surr=surr\n",
    "                )\n",
    "                v_total_loss += v_loss_dict['loss'].item()\n",
    "        \n",
    "        avg_val_loss = v_total_loss / len(val_loader)\n",
    "        \n",
    "        # Pruning: 성능이 개선되지 않는 trial은 조기 종료하여 시간 절약\n",
    "        trial.report(avg_val_loss, epoch)\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return avg_val_loss\n",
    "\n",
    "# 4. 최적화 실행\n",
    "# n_trials: 총 시도 횟수 (예: 30)\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=30)\n",
    "\n",
    "# 5. 최적화 결과 확인 및 모델 재학습 활용\n",
    "print(\"-\" * 30)\n",
    "print(\"Best hyperparameters:\", study.best_params)\n",
    "print(\"Best validation loss:\", study.best_value)\n",
    "\n",
    "# 6. (선택) 파라미터 중요도 시각화\n",
    "# optuna.visualization.plot_param_importances(study).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
