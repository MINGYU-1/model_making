{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fda2f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "par_dir = os.path.abspath(os.path.join(os.getcwd(),os.pardir))\n",
    "os.chdir(par_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91885487",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-27 23:43:37,666]\u001b[0m A new study created in memory with name: no-name-d428a3d6-b347-467c-8d11-03841747fcd4\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-27 23:45:17,417]\u001b[0m Trial 0 finished with value: 9.18458752883108 and parameters: {'lr': 0.004648759664352172, 'z_dim': 22, 'z2_dim': 11, 'z3_dim': 4, 'a': 4.318959792691114, 'b': 1.8936675449025635, 'c': 3.629307136673087, 'd': 32.189983998163584, 'e': 0.11315519450009419, 'f': 0.4795986700174728, 'g': 0.21467061468041798}. Best is trial 0 with value: 9.18458752883108.\u001b[0m\n",
      "\u001b[32m[I 2026-01-27 23:46:54,824]\u001b[0m Trial 1 finished with value: 17.322511171039782 and parameters: {'lr': 0.0008096566822777182, 'z_dim': 36, 'z2_dim': 23, 'z3_dim': 6, 'a': 9.71323163926205, 'b': 0.7921325295056802, 'c': 1.837492180388947, 'd': 14.766240134328434, 'e': 0.49988896915685066, 'f': 0.8877180394645845, 'g': 0.5604866061767895}. Best is trial 0 with value: 9.18458752883108.\u001b[0m\n",
      "\u001b[32m[I 2026-01-27 23:48:35,643]\u001b[0m Trial 2 finished with value: 38.594361756977285 and parameters: {'lr': 0.00029490533066802403, 'z_dim': 27, 'z2_dim': 26, 'z3_dim': 6, 'a': 5.016942854263777, 'b': 0.6774950129496953, 'c': 4.231779738851433, 'd': 22.59048228754853, 'e': 0.2645639146745249, 'f': 0.991078320250352, 'g': 0.8907197130188999}. Best is trial 0 with value: 9.18458752883108.\u001b[0m\n",
      "\u001b[32m[I 2026-01-27 23:49:59,988]\u001b[0m Trial 3 finished with value: 77.24167372051038 and parameters: {'lr': 0.0001999872533950771, 'z_dim': 24, 'z2_dim': 24, 'z3_dim': 7, 'a': 8.843215661320347, 'b': 0.4818115702371547, 'c': 3.345465183846078, 'd': 32.530327295361815, 'e': 0.9841007814902627, 'f': 0.40494499355819413, 'g': 0.7191007752486056}. Best is trial 0 with value: 9.18458752883108.\u001b[0m\n",
      "\u001b[32m[I 2026-01-27 23:51:57,599]\u001b[0m Trial 4 finished with value: 7.1642077847530965 and parameters: {'lr': 0.003903633289309598, 'z_dim': 18, 'z2_dim': 23, 'z3_dim': 9, 'a': 8.910919805770074, 'b': 1.027215636552544, 'c': 1.5271087321263774, 'd': 13.125035889134233, 'e': 0.2846943796637129, 'f': 0.8638178891482876, 'g': 0.19981213748555388}. Best is trial 4 with value: 7.1642077847530965.\u001b[0m\n",
      "\u001b[32m[I 2026-01-27 23:51:59,484]\u001b[0m Trial 5 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-27 23:53:25,913]\u001b[0m Trial 6 finished with value: 5.290164533414338 and parameters: {'lr': 0.0017172153142977133, 'z_dim': 36, 'z2_dim': 9, 'z3_dim': 16, 'a': 1.041469470037605, 'b': 0.17570462073692372, 'c': 4.627324516504179, 'd': 10.025058559180522, 'e': 0.25021505123233095, 'f': 0.666581439911554, 'g': 0.9297802624840975}. Best is trial 6 with value: 5.290164533414338.\u001b[0m\n",
      "\u001b[32m[I 2026-01-27 23:53:37,838]\u001b[0m Trial 7 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-27 23:53:40,225]\u001b[0m Trial 8 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-27 23:53:42,389]\u001b[0m Trial 9 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-27 23:53:44,197]\u001b[0m Trial 10 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-27 23:55:13,519]\u001b[0m Trial 11 finished with value: 7.348090924714741 and parameters: {'lr': 0.001664486582328159, 'z_dim': 34, 'z2_dim': 19, 'z3_dim': 12, 'a': 7.063289614367248, 'b': 1.1050008109289051, 'c': 1.0569876753051808, 'd': 10.308558850663456, 'e': 0.11011071300836142, 'f': 0.6829000381039586, 'g': 0.1303672539414577}. Best is trial 6 with value: 5.290164533414338.\u001b[0m\n",
      "\u001b[32m[I 2026-01-27 23:55:36,837]\u001b[0m Trial 12 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-27 23:55:38,528]\u001b[0m Trial 13 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-27 23:55:40,543]\u001b[0m Trial 14 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-27 23:55:54,262]\u001b[0m Trial 15 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-27 23:55:55,916]\u001b[0m Trial 16 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-27 23:55:57,361]\u001b[0m Trial 17 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-27 23:55:58,813]\u001b[0m Trial 18 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-27 23:56:00,543]\u001b[0m Trial 19 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-27 23:56:17,202]\u001b[0m Trial 20 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-27 23:56:35,439]\u001b[0m Trial 21 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-27 23:56:38,930]\u001b[0m Trial 22 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-27 23:58:19,019]\u001b[0m Trial 23 finished with value: 6.913314643659089 and parameters: {'lr': 0.00493883672871473, 'z_dim': 31, 'z2_dim': 27, 'z3_dim': 16, 'a': 8.715536471985263, 'b': 1.373669202355067, 'c': 2.092077341190965, 'd': 13.289024067054761, 'e': 0.29555470104695514, 'f': 0.6340895127039916, 'g': 0.267332882873495}. Best is trial 6 with value: 5.290164533414338.\u001b[0m\n",
      "\u001b[32m[I 2026-01-27 23:58:21,081]\u001b[0m Trial 24 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-27 23:58:22,723]\u001b[0m Trial 25 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-27 23:58:26,715]\u001b[0m Trial 26 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-28 00:00:07,005]\u001b[0m Trial 27 finished with value: 4.972087835010729 and parameters: {'lr': 0.004910076924668725, 'z_dim': 38, 'z2_dim': 24, 'z3_dim': 16, 'a': 9.972887394351094, 'b': 0.2850579569357288, 'c': 2.7213132264567905, 'd': 12.987850364311381, 'e': 0.21831316375889556, 'f': 0.1360006434644352, 'g': 0.18892902408005896}. Best is trial 27 with value: 4.972087835010729.\u001b[0m\n",
      "\u001b[32m[I 2026-01-28 00:00:08,656]\u001b[0m Trial 28 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-28 00:00:10,288]\u001b[0m Trial 29 pruned. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Best hyperparameters: {'lr': 0.004910076924668725, 'z_dim': 38, 'z2_dim': 24, 'z3_dim': 16, 'a': 9.972887394351094, 'b': 0.2850579569357288, 'c': 2.7213132264567905, 'd': 12.987850364311381, 'e': 0.21831316375889556, 'f': 0.1360006434644352, 'g': 0.18892902408005896}\n",
      "Best validation loss: 4.972087835010729\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import joblib\n",
    "import optuna\n",
    "from model.m27odel import MultiDecoderCondVAE\n",
    "from loss.l27oss_all import integrated_loss_fn\n",
    "\n",
    "# 1. 환경 및 데이터 준비\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 데이터 로더 및 스케일러 로드\n",
    "x_scaler = joblib.load('torch/a_27_x_scaler.pkl')\n",
    "x2_scaler = joblib.load('torch/s_27_x2_scaler.pkl')\n",
    "x3_scaler = joblib.load('torch/s_27_x3_scaler.pkl')\n",
    "c_saler = joblib.load('torch/a_27_c_scaler.pkl')\n",
    "train_loader = torch.load('torch/train_loader_all.pt', weights_only=False)\n",
    "val_loader = torch.load('torch/val_loader_all.pt', weights_only=False)\n",
    "\n",
    "# 입력 차원 자동 추출 (첫 번째 배치를 통해 확인)\n",
    "x_sample,x2_sample,x3_sample, c_sample = next(iter(train_loader))\n",
    "x_dim = x_sample.shape[1]\n",
    "x2_dim = x2_sample.shape[1]\n",
    "x3_dim = x3_sample.shape[1]\n",
    "c_dim = c_sample.shape[1]\n",
    "\n",
    "def objective(trial):\n",
    "    # 하이퍼파라미터 제안\n",
    "    lr = trial.suggest_float(\"lr\", 1e-4, 5e-3, log=True)\n",
    "    \n",
    "    # 구조적 차원 (계층 구조 반영)\n",
    "    z_dim = trial.suggest_int(\"z_dim\", 16, 48)\n",
    "    z2_dim = trial.suggest_int(\"z2_dim\", 8, 32)\n",
    "    z3_dim = trial.suggest_int(\"z3_dim\", 4, 16)\n",
    "\n",
    "    # 가중치 (Loss Balancing)\n",
    "    a = trial.suggest_float(\"a\", 1.0, 10.0)   # x 복원 (중요)\n",
    "    b = trial.suggest_float(\"b\", 0.1, 2.0)    # x2 복원\n",
    "    c = trial.suggest_float(\"c\", 1.0, 5.0)    # x3 복원\n",
    "    d = trial.suggest_float(\"d\", 10.0, 50.0)  # BCE 확률 예측 (가장 중요할 경우)\n",
    "    \n",
    "    # KL 가중치는 상대적으로 작게 관리 (정규화 강도 제어)\n",
    "    e = trial.suggest_float(\"e\", 0.1, 1.0)\n",
    "    f = trial.suggest_float(\"f\", 0.1, 1.0)\n",
    "    g = trial.suggest_float(\"g\", 0.1, 1.0)\n",
    "    # 3. 모델 및 옵티마이저 선언\n",
    "    model = MultiDecoderCondVAE(x_dim,x2_dim,x3_dim, c_dim, z_dim, z2_dim,z3_dim).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    # 각 trial당 학습할 에포크 수 (성능 확인을 위해 최소 20~50회 권장)\n",
    "    epochs = 50 \n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # --- Training Loop ---\n",
    "        model.train()\n",
    "        for x, x2,x3,c in train_loader:\n",
    "            x, x2,x3, c = x.to(device),x2.to(device),x3.to(device), c.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            bce_logit ,binary_out, x_hat,x2_hat,x3_hat, z_mu,z_logvar,z2_mu,z2_logvar,z3_mu,z3_logvar = model( x,x2,x3, c)\n",
    "            \n",
    "            # integrated_loss_fn에 제안된 가중치 적용\n",
    "            loss_dict = integrated_loss_fn(\n",
    "                bce_logit, x_hat, x2_hat,x3_hat,x,x2,x3, z_mu, z_logvar,z2_mu,z2_logvar,z3_mu,z3_logvar,\n",
    "                a=a, b=b,c=c,d=d,e=e,f=f,g=g\n",
    "            )\n",
    "            \n",
    "            loss_dict['loss'].mean().backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        # --- Validation Loop ---\n",
    "        model.eval()\n",
    "        v_total_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for v_x,v2_x,v3_x, v_c in val_loader:\n",
    "                v_x,v2_x,v3_x, v_c = v_x.to(device),v2_x.to(device),v3_x.to(device), v_c.to(device)\n",
    "                v_bce_logit,v_binary_out,v_x_hat,v2_x_hat,v3_x_hat,v_mu,v_logvar,v2_mu,v2_logvar,v3_mu,v3_logvar = model(v_x,v2_x,v3_x, v_c)\n",
    "                \n",
    "                v_loss_dict = integrated_loss_fn(\n",
    "                    v_bce_logit, v_x_hat,v2_x_hat,v3_x_hat, v_x,v2_x,v3_x, v_mu, v_logvar,v2_mu,v2_logvar,v3_mu,v3_logvar,a=a,b=b,c=c,d=d,e=e,f=f,g=g)\n",
    "                v_total_loss += v_loss_dict['loss'].mean().item()\n",
    "        \n",
    "        avg_val_loss = v_total_loss / len(val_loader)\n",
    "        \n",
    "        # Pruning: 성능이 개선되지 않는 trial은 조기 종료하여 시간 절약\n",
    "        trial.report(avg_val_loss, epoch)\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return avg_val_loss\n",
    "\n",
    "# 4. 최적화 실행\n",
    "# n_trials: 총 시도 횟수 (예: 30)\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=30)\n",
    "\n",
    "# 5. 최적화 결과 확인 및 모델 재학습 활용\n",
    "print(\"-\" * 30)\n",
    "print(\"Best hyperparameters:\", study.best_params)\n",
    "print(\"Best validation loss:\", study.best_value)\n",
    "\n",
    "# 6. (선택) 파라미터 중요도 시각화\n",
    "# optuna.visualization.plot_param_importances(study).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
