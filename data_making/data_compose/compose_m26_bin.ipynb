{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3875e87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "par_dir = os.path.abspath(os.path.join(os.getcwd(),os.pardir))\n",
    "os.chdir(par_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "decfa692",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'model'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m r2_score\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmodel\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mm26_bin\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MultiDecoderCondVAE\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mloss\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01ml26oss_all\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m integrated_loss_fn\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvae_earlystopping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m EarlyStopping\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'model'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.preprocessing import StandardScaler, MaxAbsScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from model.m26_bin import MultiDecoderCondVAE\n",
    "from loss.l26oss_all import integrated_loss_fn\n",
    "from vae_earlystopping import EarlyStopping\n",
    "\n",
    "def draw_boxplot(scores, title=\"R2 scores (test)\"):\n",
    "    plt.figure()\n",
    "    plt.boxplot(scores, vert=True)\n",
    "    plt.ylabel(\"R2\")\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "x_data = np.load('./data/metal.npy')\n",
    "c_data = np.load('./data/pre_re.npy')\n",
    "# s_data = np.load('./data/support.npy')  # 현재 코드에서는 안 쓰고 있습니다.\n",
    "\n",
    "r2_scores = []\n",
    "seeds = torch.randint(1, 100, (20,))\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "for n in seeds:\n",
    "    seed = int(n)\n",
    "\n",
    "    # split\n",
    "    x_train, x_test, c_train, c_test = train_test_split(\n",
    "        x_data, c_data, random_state=seed, test_size=0.4\n",
    "    )\n",
    "    x_val, x_test, c_val, c_test = train_test_split(\n",
    "        x_test, c_test, random_state=seed, test_size=0.5\n",
    "    )\n",
    "\n",
    "    # scaling (fit은 train에만)\n",
    "    x_scaler = MaxAbsScaler()\n",
    "    c_scaler = StandardScaler()\n",
    "\n",
    "    x_train = x_scaler.fit_transform(x_train)\n",
    "    c_train = c_scaler.fit_transform(c_train)\n",
    "\n",
    "    x_val = x_scaler.transform(x_val)\n",
    "    x_test = x_scaler.transform(x_test)\n",
    "    c_val = c_scaler.transform(c_val)\n",
    "    c_test = c_scaler.transform(c_test)\n",
    "\n",
    "    # torch tensors\n",
    "    x_train = torch.tensor(x_train, dtype=torch.float32)\n",
    "    x_val   = torch.tensor(x_val,   dtype=torch.float32)\n",
    "    x_test  = torch.tensor(x_test,  dtype=torch.float32)\n",
    "\n",
    "    c_train = torch.tensor(c_train, dtype=torch.float32)\n",
    "    c_val   = torch.tensor(c_val,   dtype=torch.float32)\n",
    "    c_test  = torch.tensor(c_test,  dtype=torch.float32)\n",
    "\n",
    "    # loaders (train은 보통 shuffle=True 권장)\n",
    "    train_loader = DataLoader(TensorDataset(x_train, c_train), batch_size=64, shuffle=True)\n",
    "    val_loader   = DataLoader(TensorDataset(x_val,   c_val),   batch_size=64, shuffle=False)\n",
    "    test_loader  = DataLoader(TensorDataset(x_test,  c_test),  batch_size=64, shuffle=False)\n",
    "\n",
    "    # model\n",
    "    x_dim = x_train.shape[1]\n",
    "    c_dim = c_train.shape[1]\n",
    "    model = MultiDecoderCondVAE(x_dim, c_dim, z_dim=8).to(device)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "    early_stopping = EarlyStopping(patience=40, min_delta=1e-9)\n",
    "\n",
    "    history = {\n",
    "        'train_loss': [], 'train_bce': [], 'train_mse': [], 'train_kl': [],\n",
    "        'val_loss': [],   'val_bce': [],   'val_mse': [],   'val_kl': []\n",
    "    }\n",
    "\n",
    "    epochs = 600\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        # ---------- train (epoch) ----------\n",
    "        model.train()\n",
    "        t_loss = t_mse = t_bce = t_kl = 0.0\n",
    "\n",
    "        for x, c in train_loader:\n",
    "            x, c = x.to(device), c.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            bce_logit, binary_out, x_hat, z_mu, z_logvar = model(x, c)\n",
    "            loss_dict = integrated_loss_fn(bce_logit, x_hat, x, z_mu, z_logvar)\n",
    "\n",
    "            loss_dict['loss'].backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            t_loss += loss_dict['loss'].item()\n",
    "            t_mse  += loss_dict['mse_loss'].item()\n",
    "            t_bce  += loss_dict['bce_loss'].item()\n",
    "            t_kl   += loss_dict['kl_loss'].item()\n",
    "\n",
    "        avg_train_loss = t_loss / len(train_loader)\n",
    "        history['train_loss'].append(avg_train_loss)\n",
    "        history['train_mse'].append(t_mse / len(train_loader))\n",
    "        history['train_bce'].append(t_bce / len(train_loader))\n",
    "        history['train_kl'].append(t_kl / len(train_loader))\n",
    "\n",
    "        # ---------- val (epoch) ----------\n",
    "        model.eval()\n",
    "        v_loss = v_mse = v_bce = v_kl = 0.0\n",
    "        with torch.no_grad():\n",
    "            for v_x, v_c in val_loader:\n",
    "                v_x, v_c = v_x.to(device), v_c.to(device)\n",
    "                v_bce_logit, v_binary_out, v_x_hat, v_mu, v_logvar = model(v_x, v_c)\n",
    "                loss_dict = integrated_loss_fn(v_bce_logit, v_x_hat, v_x, v_mu, v_logvar)\n",
    "\n",
    "                v_loss += loss_dict['loss'].item()\n",
    "                v_mse  += loss_dict['mse_loss'].item()\n",
    "                v_bce  += loss_dict['bce_loss'].item()\n",
    "                v_kl   += loss_dict['kl_loss'].item()\n",
    "\n",
    "        avg_val_loss = v_loss / len(val_loader)\n",
    "        history['val_loss'].append(avg_val_loss)\n",
    "        history['val_mse'].append(v_mse / len(val_loader))\n",
    "        history['val_bce'].append(v_bce / len(val_loader))\n",
    "        history['val_kl'].append(v_kl / len(val_loader))\n",
    "\n",
    "        if epoch % 20 == 0 or epoch == 2:\n",
    "            print(f'Epoch [{epoch}/{epochs}] | Train:{avg_train_loss:.4f} | Val:{avg_val_loss:.4f}')\n",
    "\n",
    "        # early stopping (epoch 단위)\n",
    "        if early_stopping(avg_val_loss, model):\n",
    "            break\n",
    "\n",
    "    # best model 로드\n",
    "    early_stopping.load_best_model(model)\n",
    "    model.eval()\n",
    "\n",
    "    # ---------- test ----------\n",
    "    x_true = []\n",
    "    x_pred = []\n",
    "    with torch.no_grad():\n",
    "        for x_t, c_t in test_loader:\n",
    "            x_t, c_t = x_t.to(device), c_t.to(device)\n",
    "            bce_logit, binary_out, x_hat, z_mu, z_logvar = model(x_t, c_t)\n",
    "\n",
    "            prob_mask = torch.sigmoid(bce_logit)\n",
    "            x_hat = x_hat * prob_mask\n",
    "\n",
    "            x_true.append(x_t.cpu().numpy())\n",
    "            x_pred.append(x_hat.cpu().numpy())\n",
    "\n",
    "    all_x_true = np.vstack(x_true)\n",
    "    all_x_hat  = np.vstack(x_pred)\n",
    "\n",
    "    # R2: 스케일된 공간에서 계산 (원하면 raw로 바꿀 수 있음)\n",
    "    r2 = r2_score(all_x_true.flatten(), all_x_hat.flatten())\n",
    "    r2_scores.append(r2)\n",
    "\n",
    "# 결과 시각화\n",
    "draw_boxplot(r2_scores, title=\"Test R2 over 20 random splits\")\n",
    "print(\"R2 mean:\", float(np.mean(f'{r2_scores:.4f}')))\n",
    "print(\"R2 std :\", float(np.std(f'{r2_scores:.4f}')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aad1643f",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_bin = {\"r2_bin\": r2_scores}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e2d14ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "숫자 형태로 r2_metrics.json에 저장 완료!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "save_path = \"r2_metrics.json\"\n",
    "\n",
    "with open(save_path, 'a') as f:\n",
    "    # float 타입 데이터도 json.dump를 통해 안전하게 저장됩니다.\n",
    "    json.dump(r2_bin, f, indent=4)\n",
    "\n",
    "print(f\"숫자 형태로 {save_path}에 저장 완료!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
